{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Concatenate, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.layers import Bidirectional, InputLayer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "from sklearn.metrics import classification_report , precision_recall_fscore_support,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_train = pickle.load(open('../emnlp/features/arg_features_wsj_train.p','rb'))\n",
    "wsj_dev = pickle.load(open('../emnlp/features/arg_features_wsj_dev.p','rb'))\n",
    "\n",
    "brown = pickle.load(open('../emnlp/features/arg_features_brown.p','rb'))\n",
    "\n",
    "nyt_def = pickle.load(open('../emnlp/features/arg_features_nyt_def.p','rb'))\n",
    "nyt_med = pickle.load(open('../emnlp/features/arg_features_nyt_med.p','rb'))\n",
    "nyt_def_para = pickle.load(open('../emnlp/features/arg_features_nyt_def_para.p','rb'))\n",
    "nyt_med_para = pickle.load(open('../emnlp/features/arg_features_nyt_med_para.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_train_labels = np.array([int(label) for label in wsj_train['labels']])\n",
    "wsj_dev_labels = np.array([int(label) for label in wsj_dev['labels']])\n",
    "\n",
    "brown_labels = np.array([int(label) for label in brown['labels']])\n",
    "\n",
    "nyt_def_labels = np.array([int(label) for label in nyt_def['labels']])\n",
    "nyt_med_labels = np.array([int(label) for label in nyt_med['labels']])\n",
    "nyt_def_para_labels = np.array([int(label) for label in nyt_def_para['labels']])\n",
    "nyt_med_para_labels = np.array([int(label) for label in nyt_med_para['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_train_emb = np.array(pickle.load(open('../emnlp/features/wsj_train_embeddings_layer4.p','rb')))\n",
    "wsj_dev_emb = np.array(pickle.load(open('../emnlp/features/wsj_dev_embeddings_layer4.p','rb')))\n",
    "\n",
    "brown_emb = np.array(pickle.load(open('../emnlp/features/brown_embeddings_layer4.p','rb')))\n",
    "\n",
    "nyt_def_emb = np.array(pickle.load(open('../emnlp/features/nyt_def_embeddings_layer4.p','rb')))\n",
    "nyt_med_emb = np.array(pickle.load(open('../emnlp/features/nyt_med_embeddings_layer4.p','rb')))\n",
    "nyt_def_para_emb = np.array(pickle.load(open('../emnlp/features/nyt_def_para_embeddings_layer4.p','rb')))\n",
    "nyt_med_para_emb = np.array(pickle.load(open('../emnlp/features/nyt_med_para_embeddings_layer4.p','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_train_arg = extract_features_and_reorder(wsj_train)\n",
    "wsj_dev_arg = extract_features_and_reorder(wsj_dev)\n",
    "\n",
    "nyt_def_arg = extract_features_and_reorder(nyt_def)\n",
    "nyt_med_arg = extract_features_and_reorder(nyt_med)\n",
    "nyt_def_para_arg = extract_features_and_reorder(nyt_def_para)\n",
    "nyt_med_para_arg = extract_features_and_reorder(nyt_med_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 769       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model.add(Merge([model1, model2, model3, model4, model5, model6], mode='concat'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(wsj_train_emb[0].shape[0],)))\n",
    "model.add(Dense(1,activity_regularizer=l2(0.0001)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9986 - val_loss: 0.0516 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81f1e80490>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(wsj_train_emb, wsj_train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(wsj_dev_emb, wsj_dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_def\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.7950\n",
      "Test score: 0.646885335445404\n",
      "Test accuracy: 0.7950000166893005\n",
      "nyt_med\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.7875\n",
      "Test score: 0.7022445201873779\n",
      "Test accuracy: 0.7875000238418579\n",
      "nyt_def_para\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.7840\n",
      "Test score: 0.6548301577568054\n",
      "Test accuracy: 0.7839999794960022\n",
      "nyt_med_para\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7410 - accuracy: 0.7525\n",
      "Test score: 0.7410150170326233\n",
      "Test accuracy: 0.7524999976158142\n"
     ]
    }
   ],
   "source": [
    "for embeddings, labels, name in zip([nyt_def_emb, nyt_med_emb, nyt_def_para_emb, nyt_med_para_emb],\n",
    "                                    [nyt_def_labels, nyt_med_labels, nyt_def_para_labels, nyt_med_para_labels],\n",
    "                         ['nyt_def', 'nyt_med', 'nyt_def_para', 'nyt_med_para']):\n",
    "    print(name)\n",
    "#     test_features, test_labels = prepare_data(dataset)\n",
    "#     test_features = sequence.pad_sequences(test_features, maxlen=maxlen)\n",
    "    \n",
    "    score, acc = model.evaluate(embeddings, labels)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "3502 train sequences\n",
      "1000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3502, 80)\n",
      "x_test shape: (1000, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Epoch 1/5\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.3166 - accuracy: 0.8735 - val_loss: 0.2253 - val_accuracy: 0.9160\n",
      "Epoch 2/5\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2498 - accuracy: 0.9103 - val_loss: 0.2342 - val_accuracy: 0.9220\n",
      "Epoch 3/5\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2523 - accuracy: 0.9038 - val_loss: 0.2242 - val_accuracy: 0.9230\n",
      "Epoch 4/5\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2422 - accuracy: 0.9063 - val_loss: 0.2145 - val_accuracy: 0.9380\n",
      "Epoch 5/5\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.2452 - accuracy: 0.9129 - val_loss: 0.2144 - val_accuracy: 0.9250\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2144 - accuracy: 0.9250\n",
      "Test score: 0.2144295573234558\n",
      "Test accuracy: 0.925000011920929\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 3\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "# (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train, y_train, x_test, y_test = wsj_train_arg, wsj_train_labels, wsj_dev_arg, wsj_dev_labels\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SimpleRNN(128, dropout=0.2)) #, recurrent_dropout=0.5\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# model.save_weights(\"model_lstm_15ep.h5\")\n",
    "\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_def\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.2606 - accuracy: 0.9035\n",
      "Test score: 0.26058417558670044\n",
      "Test accuracy: 0.9035000205039978\n",
      "nyt_med\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.3320 - accuracy: 0.8720\n",
      "Test score: 0.3319821059703827\n",
      "Test accuracy: 0.871999979019165\n",
      "nyt_def_para\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8389 - accuracy: 0.5920\n",
      "Test score: 0.8388977646827698\n",
      "Test accuracy: 0.5920000076293945\n",
      "nyt_med_para\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8029 - accuracy: 0.6090\n",
      "Test score: 0.802855372428894\n",
      "Test accuracy: 0.609000027179718\n"
     ]
    }
   ],
   "source": [
    "# rnn_5ep\n",
    "for features, labels, name in zip([nyt_def_arg, nyt_med_arg, nyt_def_para_arg, nyt_med_para_arg],\n",
    "                                    [nyt_def_labels, nyt_med_labels, nyt_def_para_labels, nyt_med_para_labels],\n",
    "                         ['nyt_def', 'nyt_med', 'nyt_def_para', 'nyt_med_para']):\n",
    "    print(name)\n",
    "    x_test = sequence.pad_sequences(features, maxlen=maxlen)\n",
    "    score, acc = model.evaluate(x_test, labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_49 (InputLayer)           [(None, 768)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          98432       input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 80, 128)      384         input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_30 (SimpleRNN)       (None, 128)          32896       embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 256)          0           dropout_2[0][0]                  \n",
      "                                                                 simple_rnn_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            257         concatenate_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 131,969\n",
      "Trainable params: 131,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''first_input = Input(shape=(2, ))\n",
    "first_dense = Dense(1, )(first_input)\n",
    "\n",
    "second_input = Input(shape=(2, ))\n",
    "second_dense = Dense(1, )(second_input)\n",
    "\n",
    "merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "third_input = Input(shape=(1, ))\n",
    "merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])'''\n",
    "\n",
    "\n",
    "\n",
    "input_emb = Input(shape=(768,))\n",
    "dense_1 = Dense(128, activation='relu', activity_regularizer=l2(0.0001))(input_emb)\n",
    "dropout_1 = Dropout(0.5)(dense_1)\n",
    "# dense_2 = Dense(128, activation='sigmoid', activity_regularizer=l2(0.0001))(input_emb)\n",
    "# dropout_2 = Dropout(0.5)(dense_1)\n",
    "\n",
    "input_arg = Input(shape=(maxlen,))\n",
    "model_arg = Embedding(max_features, 128)(input_arg)\n",
    "model_arg = SimpleRNN(128, dropout=0.2)(model_arg)\n",
    "\n",
    "merged = concatenate([dropout_1, model_arg])\n",
    "dense_pred = (Dense(1, activation='sigmoid'))(merged)\n",
    "\n",
    "model = Model(inputs=[input_emb, input_arg], outputs=dense_pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.0447 - accuracy: 0.9909 - val_loss: 0.0569 - val_accuracy: 0.9880\n",
      "Epoch 2/3\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.0201 - accuracy: 0.9986 - val_loss: 0.0553 - val_accuracy: 0.9880\n",
      "Epoch 3/3\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.0175 - accuracy: 0.9989 - val_loss: 0.0570 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81e9dd9550>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_arg = sequence.pad_sequences(wsj_train_arg, maxlen=maxlen)\n",
    "x_dev_arg = sequence.pad_sequences(wsj_dev_arg, maxlen=maxlen)\n",
    "\n",
    "model.fit([wsj_train_emb, x_train_arg], wsj_train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=([wsj_dev_emb, x_dev_arg], wsj_dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_def\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9998 - accuracy: 0.7855\n",
      "Test score: 0.999777615070343\n",
      "Test accuracy: 0.7854999899864197\n",
      "nyt_med\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0414 - accuracy: 0.7785\n",
      "Test score: 1.041422963142395\n",
      "Test accuracy: 0.7785000205039978\n",
      "nyt_def_para\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9297 - accuracy: 0.7750\n",
      "Test score: 0.9296719431877136\n",
      "Test accuracy: 0.7749999761581421\n",
      "nyt_med_para\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0192 - accuracy: 0.7445\n",
      "Test score: 1.0192060470581055\n",
      "Test accuracy: 0.7444999814033508\n"
     ]
    }
   ],
   "source": [
    "# rnn_5ep\n",
    "for emb, arg, labels, name in zip([nyt_def_emb, nyt_med_emb, nyt_def_para_emb, nyt_med_para_emb],\n",
    "                                  [nyt_def_arg, nyt_med_arg, nyt_def_para_arg, nyt_med_para_arg],\n",
    "                                  [nyt_def_labels, nyt_med_labels, nyt_def_para_labels, nyt_med_para_labels],\n",
    "                         ['nyt_def', 'nyt_med', 'nyt_def_para', 'nyt_med_para']):\n",
    "    print(name)\n",
    "    arg_seq = sequence.pad_sequences(arg, maxlen=maxlen)\n",
    "    score, acc = model.evaluate([emb, arg_seq], labels, batch_size=batch_size)\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artcile_split_and_pred_para(sentences, predictions):\n",
    "    'Retruns article splitted along with their sentences labels'\n",
    "    \n",
    "    assert len(sentences) == len(predictions)\n",
    "    \n",
    "    article, article_splits = [], []\n",
    "    for i, (sent, pred) in enumerate(zip(sentences, predictions)):\n",
    "        if sent == 'ARTICLE_SPLIT_LINE\\t0\\n':\n",
    "            article_splits.append(article)\n",
    "            article = []\n",
    "        else:\n",
    "            article.append(( sent.split('\\t')[0], int(pred.rstrip()) ))\n",
    "#             article.append(( sent, pred ))\n",
    "    \n",
    "    return article_splits\n",
    "\n",
    "\n",
    "def article_sent_labels_emb(article_sent_labels):\n",
    "    X = []\n",
    "    for _, label in article_sent_labels:\n",
    "        X.append(label)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def prepare_data(publisher_dict, pred='bert', mode='not_categorical'):\n",
    "    if pred == 'bert':\n",
    "        news_arg = artcile_split_and_pred_para(publisher_dict['news_sent'],publisher_dict['news_pred_bert'])\n",
    "        op_arg = artcile_split_and_pred_para(publisher_dict['op_sent'],publisher_dict['op_pred_bert'])\n",
    "    else: #pred=='roberta'\n",
    "        news_arg = artcile_split_and_pred_para(publisher_dict['news_sent'],publisher_dict['news_pred_roberta'])\n",
    "        op_arg = artcile_split_and_pred_para(publisher_dict['op_sent'],publisher_dict['op_pred_roberta'])\n",
    "    \n",
    "    \n",
    "    features, labels = [], []\n",
    "    for article in news_arg:\n",
    "        features.append(article_sent_labels_emb(article))\n",
    "        labels.append(0)\n",
    "    for article in op_arg:\n",
    "        features.append(article_sent_labels_emb(article))\n",
    "        labels.append(1)\n",
    "    \n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_reorder(publisher_dict, pred='bert'):\n",
    "    '''Runs extract_arg_features for both \"news\" and \"op\" types of input publisher\n",
    "        Then merges them in one list following the order in the original data'''\n",
    "    \n",
    "    original_data = publisher_dict['original_data']\n",
    "    # getting news/op articles and argumentative features\n",
    "    if pred == 'bert':\n",
    "        news_articles = artcile_split_and_pred_para(publisher_dict['news_sent'],publisher_dict['news_pred_bert'])\n",
    "        op_articles = artcile_split_and_pred_para(publisher_dict['op_sent'],publisher_dict['op_pred_bert'])\n",
    "    else: #pred=='roberta'\n",
    "        news_articles = artcile_split_and_pred_para(publisher_dict['news_sent'],publisher_dict['news_pred_roberta'])\n",
    "        op_articles = artcile_split_and_pred_para(publisher_dict['op_sent'],publisher_dict['op_pred_roberta'])\n",
    "        \n",
    "    \n",
    "    news_features, op_features = [], []\n",
    "    for article in news_articles:\n",
    "        news_features.append(article_sent_labels_emb(article))\n",
    "    for article in op_articles:\n",
    "        op_features.append(article_sent_labels_emb(article))\n",
    "    \n",
    "    assert len(news_articles) == len(news_features)\n",
    "    assert len(op_articles) == len(op_features)\n",
    "    assert len(original_data) == len(news_articles) + len(op_articles)\n",
    "#     print(len(original_data), len(news_articles), len(op_articles))\n",
    "    \n",
    "    \n",
    "    # merging the two lists into one following the ordering of the original data\n",
    "    news_iter, op_iter, features = 0, 0, []\n",
    "    for i, (article, label) in enumerate(original_data):\n",
    "    \n",
    "        if int(label) == 1:\n",
    "            features.append(op_features[op_iter])\n",
    "            if len(article) > 0:\n",
    "                try:\n",
    "                    assert op_articles[op_iter][0][0].split()[0] in article.split()[0]\n",
    "                except Exception as e:\n",
    "                    print(op_articles[op_iter][0][0].split())\n",
    "                    print(article.split())\n",
    "                    print(e)\n",
    "            assert op_iter < len(op_features)\n",
    "            op_iter += 1\n",
    "        \n",
    "        elif int(label) == 0:\n",
    "            features.append(news_features[news_iter])\n",
    "            if len(article) > 0:\n",
    "                assert article.split()[0] == news_articles[news_iter][0][0].split()[0]\n",
    "            assert news_iter < len(news_features)\n",
    "            news_iter += 1\n",
    "        \n",
    "        else:\n",
    "            print('Wrong label at line {}\\nThis statement should never be printed'.format(i))\n",
    "            break\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
